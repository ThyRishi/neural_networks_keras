{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b538c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first neural network with keras tutorial\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d86a38df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eb0dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "#Its a layer, with 12 nodes, with 8 inouts, and the activation is relu meaning that it is in the firts part of the layer\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "#Layer, 8 nodes, and just activation for the first two parts of the layer\n",
    "model.add(Dense(8, activation='relu'))\n",
    "#Layer, 1 node for output and sigmod for output layer.\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "204aeaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad7b4f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/77 [==============================] - 0s 489us/step - loss: 0.9573 - accuracy: 0.5589\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 0s 380us/step - loss: 0.6973 - accuracy: 0.6424\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 400us/step - loss: 0.6694 - accuracy: 0.6508\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 0s 386us/step - loss: 0.6391 - accuracy: 0.6529\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 385us/step - loss: 0.6218 - accuracy: 0.6684\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 0s 408us/step - loss: 0.6235 - accuracy: 0.6652\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 0s 381us/step - loss: 0.6192 - accuracy: 0.6561\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 0s 389us/step - loss: 0.6222 - accuracy: 0.6472\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 0s 389us/step - loss: 0.6170 - accuracy: 0.6438\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 0s 523us/step - loss: 0.6166 - accuracy: 0.6414\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 430us/step - loss: 0.6322 - accuracy: 0.6275\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 389us/step - loss: 0.6071 - accuracy: 0.6484\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 388us/step - loss: 0.6158 - accuracy: 0.6418\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 402us/step - loss: 0.5866 - accuracy: 0.6852\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 0s 408us/step - loss: 0.5795 - accuracy: 0.6884\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 0s 387us/step - loss: 0.6202 - accuracy: 0.6298\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 414us/step - loss: 0.6097 - accuracy: 0.6467\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 392us/step - loss: 0.5935 - accuracy: 0.6622\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 446us/step - loss: 0.5905 - accuracy: 0.6766\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 417us/step - loss: 0.6053 - accuracy: 0.6620\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 0s 406us/step - loss: 0.5644 - accuracy: 0.6832\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 0s 420us/step - loss: 0.5849 - accuracy: 0.6512\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 397us/step - loss: 0.5988 - accuracy: 0.6642\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 403us/step - loss: 0.6183 - accuracy: 0.6465\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 438us/step - loss: 0.6070 - accuracy: 0.6263\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 418us/step - loss: 0.5801 - accuracy: 0.6699\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 0s 422us/step - loss: 0.5835 - accuracy: 0.6911\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 0s 541us/step - loss: 0.5896 - accuracy: 0.6478\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 0s 417us/step - loss: 0.5834 - accuracy: 0.6764\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 0s 427us/step - loss: 0.5855 - accuracy: 0.6727\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 0s 427us/step - loss: 0.6149 - accuracy: 0.6281\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 0s 412us/step - loss: 0.5832 - accuracy: 0.6499\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 0s 404us/step - loss: 0.5792 - accuracy: 0.6813\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 0s 429us/step - loss: 0.5670 - accuracy: 0.6762\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 0s 426us/step - loss: 0.5746 - accuracy: 0.6537\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 0s 431us/step - loss: 0.5917 - accuracy: 0.6486\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 0s 499us/step - loss: 0.5531 - accuracy: 0.6824\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 0s 451us/step - loss: 0.5841 - accuracy: 0.6511\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 0s 451us/step - loss: 0.5665 - accuracy: 0.6569\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 0s 497us/step - loss: 0.5739 - accuracy: 0.6777\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 0s 490us/step - loss: 0.5624 - accuracy: 0.6773\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 0s 493us/step - loss: 0.6019 - accuracy: 0.6413\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 0s 469us/step - loss: 0.5819 - accuracy: 0.6328\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 0s 440us/step - loss: 0.5715 - accuracy: 0.6344\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 0s 476us/step - loss: 0.6087 - accuracy: 0.6277\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 0s 436us/step - loss: 0.5694 - accuracy: 0.6625\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 0s 460us/step - loss: 0.5972 - accuracy: 0.6434\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 0s 431us/step - loss: 0.6072 - accuracy: 0.6268\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 0s 423us/step - loss: 0.5607 - accuracy: 0.6756\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 0s 447us/step - loss: 0.5782 - accuracy: 0.6437\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 0s 431us/step - loss: 0.5615 - accuracy: 0.6778\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 0s 427us/step - loss: 0.5416 - accuracy: 0.6767\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 0s 487us/step - loss: 0.5736 - accuracy: 0.6347\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 0s 522us/step - loss: 0.5535 - accuracy: 0.6777\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 0s 418us/step - loss: 0.5623 - accuracy: 0.6742\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 0s 429us/step - loss: 0.5643 - accuracy: 0.6701\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 0s 424us/step - loss: 0.5560 - accuracy: 0.6744\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 0s 439us/step - loss: 0.5743 - accuracy: 0.6638\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 0s 432us/step - loss: 0.5689 - accuracy: 0.6927\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 0s 419us/step - loss: 0.5567 - accuracy: 0.6863\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 0s 428us/step - loss: 0.5445 - accuracy: 0.6755\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 0s 456us/step - loss: 0.5776 - accuracy: 0.6383\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 0s 406us/step - loss: 0.5903 - accuracy: 0.6251\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 0s 408us/step - loss: 0.5573 - accuracy: 0.6788\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 0s 412us/step - loss: 0.5530 - accuracy: 0.6932\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 0s 416us/step - loss: 0.5561 - accuracy: 0.7180\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 0s 412us/step - loss: 0.5603 - accuracy: 0.7131\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 0s 410us/step - loss: 0.5639 - accuracy: 0.7188\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 0s 414us/step - loss: 0.5506 - accuracy: 0.7202\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 0s 396us/step - loss: 0.5778 - accuracy: 0.6984\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 0s 420us/step - loss: 0.5541 - accuracy: 0.7257\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 0s 396us/step - loss: 0.5356 - accuracy: 0.7446\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 0s 395us/step - loss: 0.5607 - accuracy: 0.7310\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 0s 403us/step - loss: 0.5440 - accuracy: 0.7403\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 0s 430us/step - loss: 0.5699 - accuracy: 0.7276\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 0s 413us/step - loss: 0.5360 - accuracy: 0.7444\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 0s 404us/step - loss: 0.5461 - accuracy: 0.7424\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 0s 408us/step - loss: 0.5282 - accuracy: 0.7351\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 0s 400us/step - loss: 0.5681 - accuracy: 0.7272\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 0s 438us/step - loss: 0.5480 - accuracy: 0.7366\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 388us/step - loss: 0.5491 - accuracy: 0.7374\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 0s 419us/step - loss: 0.5469 - accuracy: 0.7471\n",
      "Epoch 83/150\n",
      "77/77 [==============================] - 0s 399us/step - loss: 0.5348 - accuracy: 0.7363\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 0s 404us/step - loss: 0.5084 - accuracy: 0.7393\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 0s 395us/step - loss: 0.5489 - accuracy: 0.7298\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 0s 400us/step - loss: 0.5395 - accuracy: 0.7438\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 0s 407us/step - loss: 0.5449 - accuracy: 0.7462\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 0s 423us/step - loss: 0.5208 - accuracy: 0.7579\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 0s 471us/step - loss: 0.5352 - accuracy: 0.7442\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 0s 442us/step - loss: 0.5331 - accuracy: 0.7572\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 0s 456us/step - loss: 0.5366 - accuracy: 0.7495\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 0s 422us/step - loss: 0.5485 - accuracy: 0.7441\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 0s 416us/step - loss: 0.5479 - accuracy: 0.7404\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 0s 403us/step - loss: 0.5608 - accuracy: 0.7476\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 0s 385us/step - loss: 0.5540 - accuracy: 0.7333\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 0s 391us/step - loss: 0.5384 - accuracy: 0.7576\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 0s 396us/step - loss: 0.5179 - accuracy: 0.7585\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 0s 457us/step - loss: 0.5400 - accuracy: 0.7549\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 0s 402us/step - loss: 0.5408 - accuracy: 0.7515\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 0s 396us/step - loss: 0.5347 - accuracy: 0.7442\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 0s 398us/step - loss: 0.5331 - accuracy: 0.7322\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 0s 402us/step - loss: 0.5452 - accuracy: 0.7422\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 0s 404us/step - loss: 0.5308 - accuracy: 0.7277\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 0s 412us/step - loss: 0.5362 - accuracy: 0.7181\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 0s 403us/step - loss: 0.5420 - accuracy: 0.7517\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 0s 418us/step - loss: 0.5751 - accuracy: 0.7029\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 0s 398us/step - loss: 0.5634 - accuracy: 0.7193\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 0s 428us/step - loss: 0.5517 - accuracy: 0.7328\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 0s 413us/step - loss: 0.5504 - accuracy: 0.7532\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 0s 414us/step - loss: 0.5523 - accuracy: 0.7370\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 0s 400us/step - loss: 0.5303 - accuracy: 0.7481\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 0s 397us/step - loss: 0.5013 - accuracy: 0.7782\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 0s 407us/step - loss: 0.5146 - accuracy: 0.7588\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 0s 401us/step - loss: 0.5436 - accuracy: 0.7240\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 0s 425us/step - loss: 0.5515 - accuracy: 0.7229\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 0s 422us/step - loss: 0.5128 - accuracy: 0.7605\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 0s 461us/step - loss: 0.4978 - accuracy: 0.7805\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 0s 419us/step - loss: 0.5388 - accuracy: 0.7591\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 0s 424us/step - loss: 0.5311 - accuracy: 0.7384\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 0s 398us/step - loss: 0.5316 - accuracy: 0.7204\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 0s 406us/step - loss: 0.5431 - accuracy: 0.7292\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 0s 397us/step - loss: 0.5246 - accuracy: 0.7593\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 0s 415us/step - loss: 0.5452 - accuracy: 0.7542\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 0s 421us/step - loss: 0.5560 - accuracy: 0.6975\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 0s 418us/step - loss: 0.4952 - accuracy: 0.7584\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 0s 477us/step - loss: 0.5210 - accuracy: 0.7357\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 0s 423us/step - loss: 0.5154 - accuracy: 0.7320\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 0s 455us/step - loss: 0.5395 - accuracy: 0.7419\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 0s 435us/step - loss: 0.5342 - accuracy: 0.7678\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 0s 440us/step - loss: 0.4945 - accuracy: 0.7820\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 0s 408us/step - loss: 0.5010 - accuracy: 0.7588\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 0s 402us/step - loss: 0.5278 - accuracy: 0.7640\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 0s 412us/step - loss: 0.5408 - accuracy: 0.7579\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 0s 416us/step - loss: 0.5016 - accuracy: 0.7499\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 0s 446us/step - loss: 0.5126 - accuracy: 0.7672\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 0s 432us/step - loss: 0.5052 - accuracy: 0.7667\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 0s 432us/step - loss: 0.5312 - accuracy: 0.7380\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 0s 403us/step - loss: 0.5034 - accuracy: 0.7623\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 0s 390us/step - loss: 0.5122 - accuracy: 0.7599\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 0s 414us/step - loss: 0.5090 - accuracy: 0.7608\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 0s 403us/step - loss: 0.5060 - accuracy: 0.7560\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 0s 405us/step - loss: 0.5113 - accuracy: 0.7493\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 0s 419us/step - loss: 0.5004 - accuracy: 0.7684\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 0s 432us/step - loss: 0.5177 - accuracy: 0.7459\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 0s 426us/step - loss: 0.5176 - accuracy: 0.7560\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 0s 415us/step - loss: 0.5140 - accuracy: 0.7456\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 0s 415us/step - loss: 0.4967 - accuracy: 0.7453\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 0s 412us/step - loss: 0.5248 - accuracy: 0.7370\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 0s 409us/step - loss: 0.5637 - accuracy: 0.6979\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 0s 350us/step - loss: 0.5189 - accuracy: 0.7523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcde004bc40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9a89c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 359us/step - loss: 0.5059 - accuracy: 0.7604\n",
      "Accuracy: 76.04\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96666459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] => 1 (expected 1)\n",
      "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] => 0 (expected 0)\n",
      "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] => 1 (expected 1)\n",
      "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] => 0 (expected 0)\n",
      "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] => 1 (expected 1)\n",
      "[5.0, 116.0, 74.0, 0.0, 0.0, 25.6, 0.201, 30.0] => 0 (expected 0)\n",
      "[3.0, 78.0, 50.0, 32.0, 88.0, 31.0, 0.248, 26.0] => 0 (expected 1)\n",
      "[10.0, 115.0, 0.0, 0.0, 0.0, 35.3, 0.134, 29.0] => 1 (expected 0)\n",
      "[2.0, 197.0, 70.0, 45.0, 543.0, 30.5, 0.158, 53.0] => 1 (expected 1)\n",
      "[8.0, 125.0, 96.0, 0.0, 0.0, 0.0, 0.232, 54.0] => 0 (expected 1)\n",
      "[4.0, 110.0, 92.0, 0.0, 0.0, 37.6, 0.191, 30.0] => 0 (expected 0)\n",
      "[10.0, 168.0, 74.0, 0.0, 0.0, 38.0, 0.537, 34.0] => 1 (expected 1)\n",
      "[10.0, 139.0, 80.0, 0.0, 0.0, 27.1, 1.441, 57.0] => 0 (expected 0)\n",
      "[1.0, 189.0, 60.0, 23.0, 846.0, 30.1, 0.398, 59.0] => 1 (expected 1)\n",
      "[5.0, 166.0, 72.0, 19.0, 175.0, 25.8, 0.587, 51.0] => 1 (expected 1)\n",
      "[7.0, 100.0, 0.0, 0.0, 0.0, 30.0, 0.484, 32.0] => 0 (expected 1)\n",
      "[0.0, 118.0, 84.0, 47.0, 230.0, 45.8, 0.551, 31.0] => 1 (expected 1)\n",
      "[7.0, 107.0, 74.0, 0.0, 0.0, 29.6, 0.254, 31.0] => 0 (expected 1)\n",
      "[1.0, 103.0, 30.0, 38.0, 83.0, 43.3, 0.183, 33.0] => 1 (expected 0)\n",
      "[1.0, 115.0, 70.0, 30.0, 96.0, 34.6, 0.529, 32.0] => 0 (expected 1)\n",
      "[3.0, 126.0, 88.0, 41.0, 235.0, 39.3, 0.704, 27.0] => 0 (expected 0)\n",
      "[8.0, 99.0, 84.0, 0.0, 0.0, 35.4, 0.388, 50.0] => 0 (expected 0)\n",
      "[7.0, 196.0, 90.0, 0.0, 0.0, 39.8, 0.451, 41.0] => 1 (expected 1)\n",
      "[9.0, 119.0, 80.0, 35.0, 0.0, 29.0, 0.263, 29.0] => 0 (expected 1)\n",
      "[11.0, 143.0, 94.0, 33.0, 146.0, 36.6, 0.254, 51.0] => 1 (expected 1)\n",
      "[10.0, 125.0, 70.0, 26.0, 115.0, 31.1, 0.205, 41.0] => 1 (expected 1)\n",
      "[7.0, 147.0, 76.0, 0.0, 0.0, 39.4, 0.257, 43.0] => 1 (expected 1)\n",
      "[1.0, 97.0, 66.0, 15.0, 140.0, 23.2, 0.487, 22.0] => 0 (expected 0)\n",
      "[13.0, 145.0, 82.0, 19.0, 110.0, 22.2, 0.245, 57.0] => 0 (expected 0)\n",
      "[5.0, 117.0, 92.0, 0.0, 0.0, 34.1, 0.337, 38.0] => 0 (expected 0)\n",
      "[5.0, 109.0, 75.0, 26.0, 0.0, 36.0, 0.546, 60.0] => 1 (expected 0)\n",
      "[3.0, 158.0, 76.0, 36.0, 245.0, 31.6, 0.851, 28.0] => 1 (expected 1)\n",
      "[3.0, 88.0, 58.0, 11.0, 54.0, 24.8, 0.267, 22.0] => 0 (expected 0)\n",
      "[6.0, 92.0, 92.0, 0.0, 0.0, 19.9, 0.188, 28.0] => 0 (expected 0)\n",
      "[10.0, 122.0, 78.0, 31.0, 0.0, 27.6, 0.512, 45.0] => 1 (expected 0)\n",
      "[4.0, 103.0, 60.0, 33.0, 192.0, 24.0, 0.966, 33.0] => 1 (expected 0)\n",
      "[11.0, 138.0, 76.0, 0.0, 0.0, 33.2, 0.42, 35.0] => 1 (expected 0)\n",
      "[9.0, 102.0, 76.0, 37.0, 0.0, 32.9, 0.665, 46.0] => 1 (expected 1)\n",
      "[2.0, 90.0, 68.0, 42.0, 0.0, 38.2, 0.503, 27.0] => 0 (expected 1)\n",
      "[4.0, 111.0, 72.0, 47.0, 207.0, 37.1, 1.39, 56.0] => 1 (expected 1)\n",
      "[3.0, 180.0, 64.0, 25.0, 70.0, 34.0, 0.271, 26.0] => 1 (expected 0)\n",
      "[7.0, 133.0, 84.0, 0.0, 0.0, 40.2, 0.696, 37.0] => 0 (expected 0)\n",
      "[7.0, 106.0, 92.0, 18.0, 0.0, 22.7, 0.235, 48.0] => 0 (expected 0)\n",
      "[9.0, 171.0, 110.0, 24.0, 240.0, 45.4, 0.721, 54.0] => 1 (expected 1)\n",
      "[7.0, 159.0, 64.0, 0.0, 0.0, 27.4, 0.294, 40.0] => 1 (expected 0)\n",
      "[0.0, 180.0, 66.0, 39.0, 0.0, 42.0, 1.893, 25.0] => 1 (expected 1)\n",
      "[1.0, 146.0, 56.0, 0.0, 0.0, 29.7, 0.564, 29.0] => 1 (expected 0)\n",
      "[2.0, 71.0, 70.0, 27.0, 0.0, 28.0, 0.586, 22.0] => 0 (expected 0)\n",
      "[7.0, 103.0, 66.0, 32.0, 0.0, 39.1, 0.344, 31.0] => 1 (expected 1)\n",
      "[7.0, 105.0, 0.0, 0.0, 0.0, 0.0, 0.305, 24.0] => 0 (expected 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishiatreya/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(X)\n",
    "# summarize the first 5 cases\n",
    "for i in range(50):\n",
    "\tprint('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d5c641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
